import streamlit as st
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
from pathlib import Path
from sklearn.metrics import (
    roc_curve, auc,
    confusion_matrix,
    classification_report
)
import seaborn as sns
import torch.nn as nn
from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights
import pandas as pd
import cv2
from pathlib import Path
from utils.style import apply_custom_css
from utils.sidebar import render_sidebar

apply_custom_css()
render_sidebar()

# CSS personnalis√© pour √©largir encore plus le contenu
st.markdown("""
    <style>
        .main .block-container {
            max-width: 95%;
            padding-left: 3rem;
            padding-right: 3rem;
        }
    </style>
""", unsafe_allow_html=True)

tab1, tab2 = st.tabs(["üìã Pr√©sentation du mod√®le", "üî¨ Mod√©lisation"])

with tab1:
    st.markdown("""
    # üß† Mod√®le PatchCore + WideResNet50

    Ce syst√®me permet de **d√©tecter automatiquement des anomalies visuelles** sur des produits industriels (comme des c√¢bles, vis, bouteilles, etc.) √† partir d‚Äôimages.

    ---

    ## üì¶ Objectif

    Identifier :
    - ‚úÖ les pi√®ces **normales** (sans d√©faut)
    - ‚ùå les pi√®ces **d√©fectueuses** (t√¢che, rayure, trou, etc.)

    üëâ **Sans besoin d‚Äô√©tiqueter les d√©fauts** : on apprend uniquement sur des pi√®ces "bonnes".

    ---

    ## üß† Comment √ßa fonctionne ?

    1. ### Apprentissage (sur pi√®ces normales)
    - Le syst√®me **analyse des images de produits bons**
    - Il extrait des **"empreintes visuelles"** gr√¢ce √† un r√©seau de neurones (**WideResNet50**)
    - Ces empreintes sont enregistr√©es dans une **base m√©moire** (*memory bank*)

    2. ### Inspection (nouvelles images)
    - Chaque nouvelle pi√®ce est transform√©e en empreinte
    - Elle est **compar√©e √† la base m√©moire**
    - Si elle est **trop diff√©rente**, elle est consid√©r√©e comme **anormale**

    3. ### Seuil de d√©cision automatique
    - Le syst√®me calcule un **score d‚Äôanomalie**
    - Il **choisit un seuil optimal** pour d√©cider si la pi√®ce est OK ou NOK

    4. ### √âvaluation des r√©sultats
    - üìà Courbe ROC (pour √©valuer la qualit√© du mod√®le)
    - üîç Matrice de confusion (visualisation des erreurs)

    ---

    ## üîß Technologies utilis√©es

    - **WideResNet50** : r√©seau de neurones qui extrait une repr√©sentation riche des images
    - **PatchCore** : m√©thode de d√©tection d‚Äôanomalies visuelles par comparaison avec des exemples normaux
    - **Distance euclidienne** : mesure la diff√©rence entre une image et les images normales

    ---

    """)

    st.header("üß† Comprendre le fonctionnement de WideResNet50")

    st.image(
        "static/ResNet50.png",
        caption="Architecture r√©sum√©e de ResNet/WideResNet50 ‚Äì Source : https://commons.wikimedia.org/wiki/File:ResNet50.png",
        use_container_width=True
    )

    st.markdown("""
    ### üîç Extraction de caract√©ristiques visuelles avec WideResNet50

    Lorsque notre syst√®me analyse une image, il ne travaille pas directement avec les pixels. Il commence par **traduire visuellement l‚Äôimage en une repr√©sentation num√©rique plus intelligente**, appel√©e *vecteur de caract√©ristiques*.

    Pour cela, nous utilisons un r√©seau de neurones **pr√©-entra√Æn√©** tr√®s puissant : **WideResNet50**.

    ---

    ### üß† Pourquoi WideResNet50 ?

    WideResNet50 a √©t√© entra√Æn√© sur des millions d‚Äôimages pour apprendre √† d√©tecter automatiquement :
    - des **formes**, 
    - des **textures**,
    - des **motifs visuels complexes**.

    On l‚Äôutilise ici **comme un expert qualit√© num√©rique** :
    - Il ne prend pas de d√©cision finale,
    - Mais il **analyse l‚Äôimage** et nous donne un **r√©sum√© visuel tr√®s pr√©cis** sous forme de vecteur.

    ---

    ### ‚öôÔ∏è Comment √ßa fonctionne ?

    1. L‚Äôimage passe √† travers les couches internes du r√©seau.
    2. Certaines couches sont surveill√©es pour **extraire des informations interm√©diaires pertinentes** (appel√©es *feature maps*).
    3. Ces informations sont trait√©es (moyenn√©es, redimensionn√©es) pour former une **empreinte num√©rique unique** de l‚Äôimage.
    4. Cette empreinte permet ensuite de :
    - **d√©tecter les anomalies**,
    - ou comparer des images entre elles (**d√©tection de d√©viation** par rapport √† la norme).

    ---

    ### üß© En r√©sum√©

    C‚Äôest comme si on transformait chaque image en **carte d‚Äôidentit√© visuelle**, que l‚Äôon peut ensuite comparer :
    - Une pi√®ce "bonne" a une signature typique,
    - Une pi√®ce "d√©fectueuse" produit une signature diff√©rente,
    - Et c‚Äôest cette diff√©rence que l‚Äôon capte pour signaler une anomalie.

    """)

    st.markdown("""
    ### üîé D√©tail technique : extraction de caract√©ristiques via WideResNet50

    WideResNet50 est un r√©seau de neurones profond de type *ResNet* (Residual Network) mais **√©largi** (*wide*), ce qui signifie que chaque couche poss√®de plus de filtres pour mieux capturer la richesse des informations visuelles.

    Voici ce qui se passe quand une image est analys√©e :

    1. **Propagation dans le r√©seau**  
    L'image d'entr√©e est transform√©e en une s√©rie de repr√©sentations visuelles √† travers plusieurs couches convolutives successives.  
    Chaque couche d√©tecte des motifs de complexit√© croissante :  
    - Couches basses : contours, bords, textures simples  
    - Couches interm√©diaires : formes, motifs locaux complexes  
    - Couches hautes : objets, parties d'objets, contextes visuels  

    2. **Extraction des *feature maps***  
    Au lieu d‚Äôutiliser seulement la sortie finale du r√©seau, on intercepte les sorties de couches interm√©diaires (ici, `layer2` et `layer3`) gr√¢ce √† des *hooks*.  
    Ces *feature maps* contiennent des cartes spatiales riches en informations visuelles, capturant les d√©tails essentiels pour distinguer une pi√®ce normale d‚Äôune pi√®ce anormale.

    3. **Mise en forme des caract√©ristiques**  
    Ces *feature maps* sont moyenn√©es spatialement (via un average pooling), puis redimensionn√©es pour avoir la m√™me taille.  
    On concat√®ne ensuite toutes ces cartes pour obtenir une **empreinte visuelle unique**.  
    Cette empreinte est un vecteur multidimensionnel repr√©sentant la "signature" visuelle de l'image, condens√©e et normalis√©e.

    4. **Utilisation dans PatchCore**  
    Cette signature est compar√©e √† une base m√©moire construite sur des pi√®ces normales.  
    Plus la distance (diff√©rence) entre la signature de la pi√®ce test√©e et celles de la m√©moire est grande, plus le score d‚Äôanomalie est √©lev√©, signalant un d√©faut potentiel.

    ---

    üí° **En r√©sum√© :** WideResNet50 agit comme un d√©tective visuel expert qui transforme chaque image en une empreinte digitale visuelle complexe.  
    Cette empreinte est la cl√© pour d√©tecter automatiquement les anomalies sans que le mod√®le ait jamais vu d‚Äôexemple de d√©faut.

    """)

    st.header("üß† Comprendre le fonctionnement de PatchCore")

    st.image("static/architecture_PatchCore.png", 
             caption="Pipeline PatchCore ‚Äì Source : GitHub Amazon Science (https://github.com/amazon-science/patchcore-inspection/blob/main/images/architecture.png)", 
             use_container_width =True)

    st.markdown("""
    PatchCore est une m√©thode de **d√©tection d‚Äôanomalies visuelles** bas√©e sur l‚Äôintelligence artificielle.

    Voici une explication simple de son fonctionnement :
    - Nous entra√Ænons un mod√®le uniquement avec des **images normales** (produits sans d√©faut).
    - Ce mod√®le extrait les **caract√©ristiques visuelles importantes** de chaque image.
    - Ces caract√©ristiques sont stock√©es dans une "m√©moire".
    - Lorsqu‚Äôon re√ßoit une **nouvelle image √† inspecter**, on compare ses caract√©ristiques √† la m√©moire.
    - Si l‚Äôimage test est **trop diff√©rente**, elle est consid√©r√©e comme **anormale (d√©fectueuse)**.

    Cela permet de d√©tecter automatiquement des d√©fauts visuels sans avoir besoin d'exemples de chaque type de d√©faut !
    """)

with tab2:

    st.markdown("""
<div style='border-left: 6px solid #f39c12; padding: 0.5em; background-color: #fff3cd;'>
    <strong>‚ö†Ô∏è Version all√©g√©e de l'application :</strong><br>
    Cette d√©mo utilise uniquement la cat√©gorie <code>cable</code> du dataset <strong>MVTec AD</strong>, en raison de la limite de stockage de <strong>Streamlit Community Cloud</strong> (1 Go par app).<br>
    Pour exploiter l'ensemble du dataset avec toutes les cat√©gories, t√©l√©chargez le code complet et ex√©cutez-le localement.
</div>
""", unsafe_allow_html=True)
    
    CATEGORIES = [
        'cable'      
    ]

    category = st.selectbox("Choisir une cat√©gorie :", CATEGORIES, index=0)
    st.title(f"üîç Test Anomalies MVTec - cat√©gorie {category}")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    #data_path = Path("../../models")
    data_path = Path(__file__).parent.parent / "models"

    if not data_path.exists():
        st.error(f"Le chemin {data_path} n'existe pas.")
        st.stop()

    # -- Chargement des fichiers --
    try:
        y_true = np.load(data_path / f"{category}_wresnet50_y_true_test.npy")
        y_score = np.load(data_path / f"{category}_wresnet50_y_scores_test.npy")
        with open(data_path / f"{category}_wresnet50_best_threshold.txt", "r") as f:
            best_threshold = float(f.read().strip())
        memory_bank = torch.load(data_path / f"{category}_wresnet50_memory_bank.pt", map_location=device)
    except Exception as e:
        st.error(f"Erreur chargement fichiers: {e}")
        st.stop()

    # -- Affichage m√©triques --

    # Binarisation des pr√©dictions
    y_pred = (y_score >= best_threshold).astype(int)

    # -- ROC + Rapport de classification c√¥te √† c√¥te
    fpr, tpr, _ = roc_curve(y_true, y_score)
    roc_auc = auc(fpr, tpr)

    # Rapport brut
    report = classification_report(
        y_true, y_pred,
        target_names=["Good", "Anomaly"],
        output_dict=True
    )

    # Cr√©ation DataFrame
    df_report = pd.DataFrame(report).transpose()

    # Convertir support en int l√† o√π applicable (sauf "accuracy")
    if "support" in df_report.columns:
        df_report["support"] = df_report["support"].apply(
            lambda x: int(x) if isinstance(x, (int, float)) and not pd.isna(x) else ""
        )

    # Mise en forme
    styled_report = df_report.style.format({
        "precision": "{:.2f}",
        "recall": "{:.2f}",
        "f1-score": "{:.2f}",
        "support": "{:d}"
    }).format_index(lambda idx: idx.capitalize())  # Optionnel : met des majuscules √† Good/Anomaly

    # Affichage dans Streamlit

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### üìà Courbe ROC")
        fig_roc, ax = plt.subplots()
        ax.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.2f})")
        ax.plot([0, 1], [0, 1], "k--")
        ax.set_xlabel("Taux de faux positifs")
        ax.set_ylabel("Taux de vrais positifs")
        ax.legend()
        st.pyplot(fig_roc)

    with col2:
        st.markdown("### üîç Matrice de confusion")
        cm = confusion_matrix(y_true, y_pred)
        fig_cm, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                    xticklabels=["Good", "Anomaly"], yticklabels=["Good", "Anomaly"], ax=ax)
        ax.set_xlabel("Pr√©diction")
        ax.set_ylabel("V√©rit√© terrain")
        st.pyplot(fig_cm)


    st.markdown("### üìã Rapport de classification")
    st.dataframe(styled_report, use_container_width=True)

    # -- Chargement du mod√®le backbone (WideResNet50)
    class WideResNet50FeatureExtractor(nn.Module):
        def __init__(self):
            super().__init__()
            weights = Wide_ResNet50_2_Weights.DEFAULT
            self.model = wide_resnet50_2(weights=weights)
            self.model.eval()

            # Geler les poids
            for param in self.model.parameters():
                param.requires_grad = False

            # Enregistrer les couches pour hooks
            self.model.layer2[-1].register_forward_hook(self._hook)
            self.model.layer3[-1].register_forward_hook(self._hook)

        def _hook(self, module, input, output):
            self.features.append(output)

        def forward(self, x):
            self.features = []
            with torch.no_grad():
                _ = self.model(x)

            avg = nn.AvgPool2d(3, stride=1)
            fmap_size = self.features[0].shape[-2:]
            resize = nn.AdaptiveAvgPool2d(fmap_size)

            resized_maps = [resize(avg(fmap)) for fmap in self.features]
            patch = torch.cat(resized_maps, 1)
            return patch.reshape(patch.shape[1], -1).T  # (Nb de patches, Nb features)

    @st.cache_resource
    def load_model():
        model = WideResNet50FeatureExtractor().to(device)
        model.eval()
        return model
    

    model = load_model()

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])

        # -- Choix de la source de l'image --
    st.markdown("## üñºÔ∏è Choisir une image de test")

    source_option = st.radio("Source de l'image :", ["üìÅ Image pr√©d√©finie", "‚¨ÜÔ∏è Uploader une image"])

    image = None
    image_name = None

    if source_option == "üìÅ Image pr√©d√©finie":
        
        static_image_dir = Path("static/cable")
        image_paths = list(static_image_dir.glob("*/*.jpg")) + list(static_image_dir.glob("*/*.png"))
  
        if not image_paths:
            st.warning("Aucune image trouv√©e dans `static/cable/*/*.jpg|png`.")
            st.stop()

        # Cr√©e une liste d'options affichant la classe et le nom de l'image
        image_options = [f"{p.parent.name} / {p.name}" for p in image_paths]
        selected_image_display = st.selectbox("S√©lectionner une image :", image_options)

        # R√©cup√®re le chemin r√©el √† partir du nom choisi
        selected_image_index = image_options.index(selected_image_display)
        selected_image_path = image_paths[selected_image_index]
        selected_class = selected_image_path.parent.name
        image = Image.open(selected_image_path).convert("RGB")
        image_name = selected_image_path.name

        st.markdown(f"**Classe de l'image s√©lectionn√©e : `{selected_class}`**")


    elif source_option == "‚¨ÜÔ∏è Uploader une image":
        uploaded_file = st.file_uploader("Uploader une image (jpg/png/jpeg)")
        if uploaded_file is not None:
            image = Image.open(uploaded_file).convert("RGB")
            image_name = uploaded_file.name

    if image is not None:

        # -- Pr√©diction --
        input_tensor = transform(image).unsqueeze(0).to(device)

        with torch.no_grad():
            features = model(input_tensor)
            distances = torch.cdist(features, memory_bank, p=2)
            dist_score, _ = torch.min(distances, dim=1)
            s_star = torch.max(dist_score)
            segm_map = dist_score.view(1, 1, 28, 28)
            segm_map = torch.nn.functional.interpolate(segm_map, size=(224, 224), mode="bilinear")
            heat_map = segm_map.squeeze().cpu().numpy()
            anomaly_score = s_star.item()
            pred = int(anomaly_score >= best_threshold)
            label = ['‚úÖ OK', '‚ùå Anomaly'][pred]

        st.markdown("### R√©sultat pr√©diction")
        st.write(f"Score d'anomalie : **{anomaly_score:.2f}**")
        st.write(f"Seuil utilis√© : **{best_threshold:.2f}**")
        st.write(f"Pr√©diction : **{label}**")

        # Cr√©ation de la superposition heatmap + image originale
        original_np = np.array(image.resize((224, 224))).astype(np.uint8)

        heatmap_norm = (heat_map - np.min(heat_map)) / (np.max(heat_map) - np.min(heat_map))
        heatmap_uint8 = np.uint8(255 * heatmap_norm)
        heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)

        superposed = cv2.addWeighted(cv2.cvtColor(original_np, cv2.COLOR_RGB2BGR), 0.6,
                                    heatmap_color, 0.4, 0)
        superposed_rgb = cv2.cvtColor(superposed, cv2.COLOR_BGR2RGB)

        # Affichage en grille 2√ó2
        fig, axs = plt.subplots(2, 2, figsize=(12, 10))

        axs[0, 0].imshow(image)
        axs[0, 0].set_title("Image originale")
        axs[0, 0].axis("off")

        axs[0, 1].imshow(superposed_rgb)
        axs[0, 1].set_title("Superposition heatmap + image")
        axs[0, 1].axis("off")

        axs[1, 0].imshow(heat_map, cmap='jet')
        axs[1, 0].set_title(f"Carte de chaleur anomalie\n(score: {anomaly_score:.2f})")
        axs[1, 0].axis("off")

        seuils = [best_threshold, best_threshold * 1.2, best_threshold * 1.5]
        segm_multi = np.zeros_like(heat_map, dtype=np.uint8)
        for i, seuil in enumerate(seuils, start=1):
            segm_multi += (heat_map > seuil).astype(np.uint8)

        axs[1, 1].imshow(segm_multi, cmap='viridis', vmin=0, vmax=len(seuils))
        axs[1, 1].set_title("Segmentation multi-niveaux")
        axs[1, 1].axis("off")

        st.pyplot(fig)